name: PySpark Tests

on:
  push:
    branches: [ main ]
    paths:
      - '**.py'
      - 'requirements*.txt'
      - '.github/workflows/**'
  pull_request:
    branches: [ main ]
    paths:
      - '**.py'
      - 'requirements*.txt'
      - '.github/workflows/**'

jobs:
  test-pyspark:
    name: Test PySpark
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.11']  # Using Python 3.11 for better PySpark and Polars compatibility
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y openjdk-11-jdk
        echo "JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64" >> $GITHUB_ENV
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
        # Explicitly install PyArrow and PySpark with specific versions
        pip install "pyarrow>=11.0.0,<12.0.0"
        pip install "pyspark>=3.4.0,<4.0.0"
        # Ensure test dependencies are installed
        pip install pytest-cov
    
    - name: Run PySpark tests
      env:
        JAVA_HOME: /usr/lib/jvm/java-11-openjdk-amd64
      run: |
        python -m pytest tests/test_mondrian_pyspark.py tests/test_mondrian_pyspark_mock.py -v --cov=./ --cov-append --cov-report=xml --durations=10
