from typing import Any, List, Dict, Optional, Union, TypeVar, Generic, Callable, Tuple, Iterator, Iterable, Set, Type, cast, overload, Protocol
from typing_extensions import Literal, TypeAlias
import pandas as pd  # Add pandas import for type hints

# Protocol for DataFrame-like objects that can be used with PySpark
class DataFrameLike(Protocol):
    def __getitem__(self, item: Any) -> Any: ...
    def collect(self) -> List[Any]: ...
    def count(self) -> int: ...
    def show(self, n: int = ..., truncate: bool = ...) -> None: ...

# Basic types
T = TypeVar('T')
K = TypeVar('K')
V = TypeVar('V')

# Minimal DataFrame definition
class DataFrame(DataFrameLike):
    def __init__(self, *args: Any, **kwargs: Any) -> None: ...
    def count(self) -> int: ...
    def collect(self) -> List[Any]: ...
    def groupBy(self, *cols: Any) -> Any: ...
    def createOrReplaceTempView(self, name: str) -> None: ...
    def createGlobalTempView(self, name: str) -> None: ...
    def show(self, n: int = 20, truncate: bool = True, vertical: bool = False) -> None: ...
    def printSchema(self) -> None: ...
    def cache(self) -> 'DataFrame': ...
    def persist(self, storageLevel: Any = ...) -> 'DataFrame': ...
    def unpersist(self, blocking: bool = ...) -> 'DataFrame': ...
    def createTempView(self, name: str) -> None: ...
    def filter(self, condition: Any) -> 'DataFrame': ...
    def select(self, *cols: Any) -> 'DataFrame': ...
    def selectExpr(self, *expr: str) -> 'DataFrame': ...
    def drop(self, *cols: str) -> 'DataFrame': ...
    def dropDuplicates(self, subset: Optional[List[str]] = None) -> 'DataFrame': ...
    def distinct(self) -> 'DataFrame': ...
    def drop_duplicates(self, subset: Optional[List[str]] = None) -> 'DataFrame': ...
    def dropna(self, how: str = ..., thresh: int = ..., subset: Optional[List[str]] = None) -> 'DataFrame': ...
    def fillna(self, value: Any, subset: Optional[List[str]] = None) -> 'DataFrame': ...
    def replace(self, to_replace: Any, value: Any = ..., subset: Optional[List[str]] = None) -> 'DataFrame': ...
    def withColumn(self, colName: str, col: Any) -> 'DataFrame': ...
    def withColumnRenamed(self, existing: str, new: str) -> 'DataFrame': ...
    def orderBy(self, *cols: Any, **kwargs: Any) -> 'DataFrame': ...
    def sort(self, *cols: Any, **kwargs: Any) -> 'DataFrame': ...
    def limit(self, num: int) -> 'DataFrame': ...
    def take(self, num: int) -> List[Any]: ...
    def head(self, n: int = ...) -> Union[Any, List[Any]]: ...
    def first(self) -> Any: ...
    def foreach(self, f: Callable[[Any], None]) -> None: ...
    def foreachPartition(self, f: Callable[[Iterator[Any]], None]) -> None: ...
    def toPandas(self) -> Any: ...
    def rdd(self) -> Any: ...
    def registerTempTable(self, name: str) -> None: ...
    def schema(self) -> Any: ...
    def columns(self) -> List[str]: ...
    def dtypes(self) -> List[Tuple[str, str]]: ...
    def explain(self, extended: bool = ...) -> None: ...
    def isLocal(self) -> bool: ...
    def isStreaming(self) -> bool: ...
    def checkpoint(self, eager: bool = ...) -> 'DataFrame': ...
    def localCheckpoint(self, eager: bool = ...) -> 'DataFrame': ...
    def withWatermark(self, eventTime: str, delayThreshold: str) -> 'DataFrame': ...
    def hint(self, name: str, *parameters: Any) -> 'DataFrame': ...
    def to(self, table: str) -> None: ...
    def toDF(self, *cols: str) -> 'DataFrame': ...
    def intersect(self, other: 'DataFrame') -> 'DataFrame': ...
    def subtract(self, other: 'DataFrame') -> 'DataFrame': ...
    def exceptAll(self, other: 'DataFrame') -> 'DataFrame': ...
    def intersectAll(self, other: 'DataFrame') -> 'DataFrame': ...
    def union(self, other: 'DataFrame') -> 'DataFrame': ...
    def unionAll(self, other: 'DataFrame') -> 'DataFrame': ...
    def join(self, other: 'DataFrame', on: Any = None, how: str = ...) -> 'DataFrame': ...
    def crossJoin(self, other: 'DataFrame') -> 'DataFrame': ...
    def repartition(self, numPartitions: int, *cols: Any) -> 'DataFrame': ...
    def repartitionByRange(self, numPartitions: int, *cols: Any, **kwargs: Any) -> 'DataFrame': ...
    def coalesce(self, numPartitions: int) -> 'DataFrame': ...
    def randomSplit(self, weights: List[float], seed: Optional[int] = None) -> List['DataFrame']: ...
    def sample(self, withReplacement: bool, fraction: float, seed: Optional[int] = None) -> 'DataFrame': ...
    def sampleBy(self, col: str, fractions: Dict[Any, float], seed: Optional[int] = None) -> 'DataFrame': ...
    def stat(self) -> Any: ...
    def describe(self, *cols: str) -> 'DataFrame': ...
    def summary(self, *statistics: str) -> 'DataFrame': ...
    def __getitem__(self, item: Any) -> Any: ...
    def __getattr__(self, name: str) -> Any: ...

# Minimal SQLContext/SparkSession definition
class SQLContext:
    def __init__(self, *args: Any, **kwargs: Any) -> None: ...
    def createDataFrame(self, data: Any, schema: Any = ..., samplingRatio: float = ..., verifySchema: bool = ...) -> DataFrame: ...
    def table(self, tableName: str) -> DataFrame: ...
    def registerDataFrameAsTable(self, df: DataFrame, tableName: str) -> None: ...
    def dropTempTable(self, tableName: str) -> None: ...
    def cacheTable(self, tableName: str) -> None: ...
    def uncacheTable(self, tableName: str) -> None: ...
    def clearCache(self) -> None: ...
    def setConf(self, key: str, value: str) -> None: ...
    def getConf(self, key: str, defaultValue: str = ...) -> str: ...
    def sql(self, sqlQuery: str) -> DataFrame: ...

class SparkSession(SQLContext):
    def __init__(self, *args: Any, **kwargs: Any) -> None: ...
    @staticmethod
    def builder() -> Any: ...
    @property
    def version(self) -> str: ...
    def newSession(self) -> 'SparkSession': ...
    def stop(self) -> None: ...
    def createDataFrame(self, data: Any, schema: Any = ..., samplingRatio: float = ..., verifySchema: bool = ...) -> DataFrame: ...

# Minimal StructType and StructField for schema definition
class StructType:
    def __init__(self, fields: Any = ...) -> None: ...
    def add(self, field: Any, dataType: Any = ..., nullable: bool = ..., metadata: Any = ...) -> 'StructType': ...
    def json(self) -> str: ...
    def jsonValue(self) -> Dict[str, Any]: ...
    def simpleString(self) -> str: ...
    def __repr__(self) -> str: ...
    def __eq__(self, other: Any) -> bool: ...
    def __ne__(self, other: Any) -> bool: ...
    def __hash__(self) -> int: ...

class StructField:
    def __init__(self, name: str, dataType: Any, nullable: bool = ..., metadata: Any = ...) -> None: ...
    @property
    def name(self) -> str: ...
    @property
    def dataType(self) -> Any: ...
    @property
    def nullable(self) -> bool: ...
    @property
    def metadata(self) -> Dict[str, Any]: ...
    def jsonValue(self) -> Dict[str, Any]: ...
    def json(self) -> str: ...
    def __repr__(self) -> str: ...
    def __eq__(self, other: Any) -> bool: ...
    def __ne__(self, other: Any) -> bool: ...
    def __hash__(self) -> int: ...

# Minimal Column class
class Column:
    def __init__(self, *args: Any, **kwargs: Any) -> None: ...
    
    # Comparison operators
    def __eq__(self, other: Any) -> 'Column': ...  # type: ignore[override]
    def __ne__(self, other: Any) -> 'Column': ...  # type: ignore[override]
    def __lt__(self, other: Any) -> 'Column': ...
    def __le__(self, other: Any) -> 'Column': ...
    def __gt__(self, other: Any) -> 'Column': ...
    def __ge__(self, other: Any) -> 'Column': ...
    
    # Arithmetic operators
    def __add__(self, other: Any) -> 'Column': ...
    def __sub__(self, other: Any) -> 'Column': ...
    def __mul__(self, other: Any) -> 'Column': ...
    def __truediv__(self, other: Any) -> 'Column': ...
    def __mod__(self, other: Any) -> 'Column': ...
    def __pow__(self, other: Any) -> 'Column': ...
    
    # Logical operators
    def __and__(self, other: Any) -> 'Column': ...
    def __or__(self, other: Any) -> 'Column': ...
    def __invert__(self) -> 'Column': ...
    def __neg__(self) -> 'Column': ...
    
    # Column operations
    def alias(self, *alias: str, **kwargs: Any) -> 'Column': ...
    name = alias
    
    # Sorting
    def asc(self) -> 'Column': ...
    def desc(self) -> 'Column': ...
    def asc_nulls_first(self) -> 'Column': ...
    def asc_nulls_last(self) -> 'Column': ...
    def desc_nulls_first(self) -> 'Column': ...
    def desc_nulls_last(self) -> 'Column': ...
    
    # Null handling
    def isNull(self) -> 'Column': ...
    def isNotNull(self) -> 'Column': ...
    
    # Type conversion
    def cast(self, dataType: Any) -> 'Column': ...
    
    # String operations
    def like(self, other: str) -> 'Column': ...
    def rlike(self, other: str) -> 'Column': ...
    def ilike(self, other: str) -> 'Column': ...
    def contains(self, other: Any) -> 'Column': ...
    def startswith(self, other: Any) -> 'Column': ...
    def endswith(self, other: Any) -> 'Column': ...
    def substr(self, startPos: int, length: int) -> 'Column': ...
    
    # Collection operations
    def isin(self, *cols: Any) -> 'Column': ...
    
    # Conditional expressions
    def between(self, lower: Any, upper: Any) -> 'Column': ...
    def when(self, condition: Any, value: Any) -> 'Column': ...
    def otherwise(self, value: Any) -> 'Column': ...
    
    # Window functions
    def over(self, window: Any) -> 'Column': ...

# Minimal functions module
class functions:
    @staticmethod
    def col(col: Union[str, 'Column']) -> 'Column': ...
    
    @staticmethod
    def lit(col: Any) -> 'Column': ...
    
    @staticmethod
    def pandas_udf(*args: Any, **kwargs: Any) -> Any: ...
    
    class PandasUDFType:
        SCALAR: int = ...
        SCALAR_ITER: int = ...
        GROUPED_MAP: int = ...
        GROUPED_AGG: int = ...
        MAP_ITER: int = ...
        COGROUPED_MAP: int = ...

# Minimal types
class types:
    class DataType: ...
    class BinaryType(DataType): ...
    class BooleanType(DataType): ...
    class ByteType(DataType): ...
    class DateType(DataType): ...
    class DecimalType(DataType): ...
    class DoubleType(DataType): ...
    class FloatType(DataType): ...
    class IntegerType(DataType): ...
    class LongType(DataType): ...
    class ShortType(DataType): ...
    class StringType(DataType): ...
    class TimestampType(DataType): ...
    class ArrayType(DataType):
        def __init__(self, elementType: 'types.DataType', containsNull: bool = ...) -> None: ...
    class MapType(DataType):
        def __init__(self, keyType: 'types.DataType', valueType: 'types.DataType', valueContainsNull: bool = ...) -> None: ...
    class StructType(DataType):
        def __init__(self, fields: Any = ...) -> None: ...
        def add(self, field: Any, dataType: Any = ..., nullable: bool = ..., metadata: Any = ...) -> 'types.StructType': ...
    class StructField(DataType):
        def __init__(self, name: str, dataType: 'types.DataType', nullable: bool = ..., metadata: Any = ...) -> None: ...
        @property
        def name(self) -> str: ...
        @property
        def dataType(self) -> 'types.DataType': ...
        @property
        def nullable(self) -> bool: ...
        @property
        def metadata(self) -> Dict[str, Any]: ...

# Minimal Row class
class Row:
    def __init__(self, *args: Any, **kwargs: Any) -> None: ...
    def __getitem__(self, item: Any) -> Any: ...
    def __getattr__(self, name: str) -> Any: ...
    def asDict(self, recursive: bool = ...) -> Dict[str, Any]: ...
    def __eq__(self, other: Any) -> bool: ...
    def __ne__(self, other: Any) -> bool: ...
    def __repr__(self) -> str: ...
    def __hash__(self) -> int: ...
    def __len__(self) -> int: ...
    def __contains__(self, item: Any) -> bool: ...

# Minimal SparkContext
class SparkContext:
    def __init__(self, *args: Any, **kwargs: Any) -> None: ...
    def version(self) -> str: ...
    def parallelize(self, data: Any, numSlices: int = ...) -> Any: ...
    def textFile(self, path: str, minPartitions: int = ...) -> Any: ...
    def stop(self) -> None: ...
    def setLogLevel(self, logLevel: str) -> None: ...
    def getConf(self) -> Any: ...
    def setJobGroup(self, groupId: str, description: str, interruptOnCancel: bool = ...) -> None: ...
    def setCheckpointDir(self, dirName: str) -> None: ...
    def getCheckpointDir(self) -> Optional[str]: ...
    def addFile(self, path: str, recursive: bool = ...) -> None: ...
    def addPyFile(self, path: str) -> None: ...
    def setLocalProperty(self, key: str, value: str) -> None: ...
    def getLocalProperty(self, key: str) -> Optional[str]: ...
    def defaultParallelism(self) -> int: ...
    def defaultMinPartitions(self) -> int: ...
    def applicationId(self) -> str: ...
    def uiWebUrl(self) -> Optional[str]: ...
    def startTime(self) -> int: ...
    def runJob(self, *args: Any, **kwargs: Any) -> Any: ...
    def dump_profiles(self, path: str) -> None: ...
    def setSystemProperty(self, key: str, value: str) -> None: ...
